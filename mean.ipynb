{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## This function takes in the file path as input and returns a 20 length array with the mean of each\n",
    "## mfcc coefficient \n",
    "\n",
    "def compute_mean_mfcc_from_csv(file_path) :\n",
    "    mfcc_df = pd.read_csv(file_path,header = None)\n",
    "    mean_mfcc = mfcc_df.mean(axis = 1)\n",
    "    return mean_mfcc\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Vector Mean created\n"
     ]
    }
   ],
   "source": [
    "### Compiling the 20 means for each file in feature_file.csv\n",
    "\n",
    "all_means = []\n",
    "mfcc_files = glob.glob('*-MFCC.csv')\n",
    "\n",
    "for file in mfcc_files :\n",
    "    mean_mfcc = compute_mean_mfcc_from_csv(file)\n",
    "    all_means.append(mean_mfcc)\n",
    "\n",
    "mean_mfcc_df = pd.DataFrame(all_means)\n",
    "mean_mfcc_df.columns = [f'MFCC_{i+1}_mean' for i in range(mean_mfcc_df.shape[1])]\n",
    "mean_mfcc_df['file_name'] = mfcc_files\n",
    "mean_mfcc_df = mean_mfcc_df[['file_name'] + [f'MFCC_{i+1}_mean' for i in range(mean_mfcc_df.shape[1]-1)]]\n",
    "mean_mfcc_df.to_csv('feature_file.csv', index = False)\n",
    "print(\"Feature Vector Mean created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_std_from_csv(file_path) :\n",
    "    mfcc_df = pd.read_csv(file_path,header = None)\n",
    "    std_mfcc = mfcc_df.std(axis = 1)\n",
    "    return std_mfcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_paths = glob.glob(\"*-MFCC.csv\")  # Adjust the pattern if necessary\n",
    "all_features = []\n",
    "\n",
    "for file_path in file_paths:\n",
    "    # Load each MFCC CSV file\n",
    "    \n",
    "    \n",
    "    # Calculate mean and standard deviation using the functions\n",
    "    means = compute_mean_mfcc_from_csv(file_path)\n",
    "    std_devs = compute_std_from_csv(file_path)\n",
    "    \n",
    "    # Combine the file name, means, and standard deviations into one feature vector\n",
    "    features = np.concatenate(([file_path], means, std_devs))\n",
    "    all_features.append(features)\n",
    "\n",
    "columns = ['file_name'] + [f'mean_mfcc_{i+1}' for i in range(20)] + [f'std_mfcc_{i+1}' for i in range(20)]\n",
    "master_df = pd.DataFrame(all_features, columns=columns)\n",
    "master_df.to_csv(\"feature_file.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mean(df):\n",
    "    return df.mean(axis=1).values\n",
    "\n",
    "def calculate_std(df):\n",
    "    return df.std(axis=1).values\n",
    "\n",
    "def calculate_skew(df):\n",
    "    return df.skew(axis=1).fillna(0).values  # Handle NaNs by filling with 0\n",
    "\n",
    "def calculate_kurtosis(df):\n",
    "    return df.kurtosis(axis=1).fillna(0).values  # Handle NaNs by filling with 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_paths = glob.glob(\"*-MFCC.csv\")\n",
    "all_features = []\n",
    "\n",
    "for file_path in file_paths:\n",
    "    # Load each MFCC CSV file\n",
    "    df = pd.read_csv(file_path, header = None)\n",
    "    \n",
    "    # Ensure the data has 20 rows (each representing an MFCC coefficient)\n",
    "    if df.shape[0] != 20:\n",
    "        print(f\"Warning: File {file_path} does not have 20 rows for MFCC coefficients. Skipping.\")\n",
    "        continue\n",
    "\n",
    "    # Calculate each feature\n",
    "    means = calculate_mean(df)\n",
    "    std_devs = calculate_std(df)\n",
    "    skews = calculate_skew(df)\n",
    "    kurtoses = calculate_kurtosis(df)\n",
    "    \n",
    "    # Confirm each feature has exactly 20 elements\n",
    "    if len(means) == 20 and len(std_devs) == 20 and len(skews) == 20 and len(kurtoses) == 20:\n",
    "        # Combine file name, means, std devs, skews, and kurtoses\n",
    "        features = np.concatenate(([file_path], means, std_devs, skews, kurtoses))\n",
    "        all_features.append(features)\n",
    "    else:\n",
    "        print(f\"Error: Feature calculation for {file_path} did not yield 20 values for each feature.\")\n",
    "        print(f\"Means: {len(means)}, Std Devs: {len(std_devs)}, Skews: {len(skews)}, Kurtoses: {len(kurtoses)}\")\n",
    "\n",
    "# Define column names: 20 each for mean, std_dev, skew, and kurtosis\n",
    "columns = ['file_name'] + \\\n",
    "          [f'mean_mfcc_{i+1}' for i in range(20)] + \\\n",
    "          [f'std_mfcc_{i+1}' for i in range(20)] + \\\n",
    "          [f'skew_mfcc_{i+1}' for i in range(20)] + \\\n",
    "          [f'kurtosis_mfcc_{i+1}' for i in range(20)]\n",
    "\n",
    "# Ensure the length of each row matches the column count before creating DataFrame\n",
    "if all(len(features) == len(columns) for features in all_features):\n",
    "    # Create DataFrame with the computed features\n",
    "    master_df = pd.DataFrame(all_features, columns=columns)\n",
    "    # Save to master CSV file\n",
    "    master_df.to_csv(\"feature_file.csv\", index=False)\n",
    "else:\n",
    "    print(\"Error: Mismatch in the number of features and columns. Please check the feature extraction.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('feature_file.csv')\n",
    "skew_kurt_features = data[[f'skew_mfcc_{i}' for i in range(1, 21)] + [f'kurtosis_mfcc_{i}' for i in range(1, 21)]]\n",
    "scaler = StandardScaler()\n",
    "skew_kurt_scaled = scaler.fit_transform(skew_kurt_features)\n",
    "# Fit PCA without specifying n_components to check explained variance\n",
    "pca = PCA()\n",
    "skew_kurt_pca_full = pca.fit(skew_kurt_scaled)\n",
    "\n",
    "# Calculate cumulative explained variance\n",
    "explained_variance = pca.explained_variance_ratio_.cumsum()\n",
    "\n",
    "# Determine the number of components that capture desired variance (e.g., 95%)\n",
    "# n_components = (explained_variance >= 0.8).argmax() + 1  # 95% variance threshold\n",
    "n_components = 2\n",
    "# Apply PCA with the selected number of components\n",
    "pca = PCA(n_components=n_components)\n",
    "skew_kurt_pca = pca.fit_transform(skew_kurt_scaled)\n",
    "for i in range(n_components):\n",
    "    data[f'skew_kurt_pca_{i+1}'] = skew_kurt_pca[:, i]\n",
    "data.to_csv('feature_file.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
